{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "\n",
    "import myclassify\n",
    "reload(myclassify)\n",
    "from myclassify import MyFeatureSet\n",
    "from myclassify import MyCountTable\n",
    "from myclassify import merge_two_cat_columns\n",
    "from myclassify import np_combine_rare\n",
    "\n",
    "# to make reproducible results\n",
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate a bunch of feature sets\n",
    "# feature set consists:\n",
    "# Xtrain, train part of feature set\n",
    "# Xtest, test part of feature set\n",
    "# fname_list, feature names\n",
    "# find_list, feature indices\n",
    "\n",
    "# base feature set with' ROLE_ID' deleted and 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2' combined\n",
    "BASE_FSET_FILE = './cache/base_fset.pickle'\n",
    "class BaseFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        df_train = pd.read_csv('./train.csv')\n",
    "        df_test = pd.read_csv('./test.csv')\n",
    "        df_all = pd.concat([df_train.drop([u'ACTION'], axis = 1),df_test.drop([u'id'], axis = 1)], ignore_index=True)\n",
    "        merge_two_cat_columns(df_all, 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_ROLLUP_12')\n",
    "        col_keep = [u'RESOURCE', u'MGR_ID', u'ROLE_ROLLUP_12', u'ROLE_DEPTNAME', \n",
    "                    u'ROLE_TITLE', u'ROLE_FAMILY_DESC', u'ROLE_FAMILY']\n",
    "        self.fname_list = col_keep\n",
    "        self.find_list = range(len(col_keep)+1)\n",
    "        df_all = df_all[col_keep]\n",
    "        \n",
    "        df_train = df_all[:][df_all.index<len(df_train.index)]\n",
    "        df_test = df_all[:][df_all.index>=len(df_train.index)]\n",
    "        \n",
    "        self.Xtrain = df_train.values\n",
    "        self.Xtest = df_test.values\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "        \n",
    "base_fset = BaseFeatureSet()\n",
    "%time base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "print base_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base feature set with one hot encoding\n",
    "OHBASE_FSET_FILE = './cache/ohbase_fset.pickle'\n",
    "class OHBaseFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        # load base_fset\n",
    "        base_fset = BaseFeatureSet()\n",
    "        self.Xtrain, self.Xtest = base_fset.fetch_feature_set(BASE_FSET_FILE)\n",
    "        # label encoding\n",
    "        lb_encoder = preprocessing.LabelEncoder()\n",
    "        n_bf = len(base_fset.fname_list)\n",
    "        for i in xrange(n_bf):\n",
    "            lb_encoder.fit(np.hstack((self.Xtrain[:, i], self.Xtest[:, i])))\n",
    "            self.Xtrain[:, i] = lb_encoder.transform(self.Xtrain[:,i])  \n",
    "            self.Xtest[:, i] = lb_encoder.transform(self.Xtest[:, i])\n",
    "        # one hot encoding\n",
    "        oh_encoder = preprocessing.OneHotEncoder()\n",
    "        oh_encoder.fit(np.vstack((self.Xtrain, self.Xtest)))\n",
    "        self.Xtrain = oh_encoder.transform(self.Xtrain).tocsr()  \n",
    "        self.Xtest = oh_encoder.transform(self.Xtest).tocsr()\n",
    "        \n",
    "        print type(self.Xtrain)\n",
    "        \n",
    "        self.fname_list = [u'OH_'+fname for fname in base_fset.fname_list]\n",
    "        self.find_list = list(oh_encoder.feature_indices_)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "ohbase_fset = OHBaseFeatureSet()\n",
    "%time ohbase_fset.load_feature_set(OHBASE_FSET_FILE)\n",
    "print ohbase_fset.fname_list\n",
    "# print isinstance(ohbase_fset.Xtrain, scipy.sparse.csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic feature set with rare event combined and label encoded\n",
    "\n",
    "CRBASE_FSET_FILE = './cache/crbase_fset.pickle'\n",
    "class CRBaseFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        # generate from base_fset\n",
    "        base_fset = BaseFeatureSet()\n",
    "        self.Xtrain, self.Xtest = base_fset.fetch_feature_set(BASE_FSET_FILE)\n",
    "        np_combine_rare(self.Xtrain, self.Xtest)\n",
    "        self.fname_list = [u'CR_'+fname for fname in base_fset.fname_list]\n",
    "        self.find_list = range(len(self.fname_list)+1)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "crbase_fset = CRBaseFeatureSet()\n",
    "%time crbase_fset.load_feature_set(CRBASE_FSET_FILE)\n",
    "print crbase_fset.fname_list\n",
    "# print crbase_fset.find_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate count tables \n",
    "# one cout table['feature_name'][key] = appaerance of key in 'feature_name'\n",
    "# two cout table[('f_name1', 'f_name2'][key1][key2] = appaerance of (key1, key2) \n",
    "# two cout table[('f_name1', 'f_name2'][key1]['total'] = total number of unique key2 appear with key1\n",
    "# to generate counting for feature i feature set:\n",
    "# use count_table.fset_one_degree_counts(base_fset, i, COUNT_TABLE_FILE)\n",
    "# to generate percentage of (key i , key j) apperance in all (key i, 'feature j') \n",
    "# use count_table.fset_one_degree_counts(base_fset, i, j, 'per',COUNT_TABLE_FILE)\n",
    "# to generate unique number of (key i , key j) in all (key i, 'feature j') \n",
    "# use count_table.fset_one_degree_counts(base_fset, i, j, 'num',COUNT_TABLE_FILE)\n",
    "\n",
    "COUNT_TABLE_FILE = './cache/count_tb.pickle'\n",
    "count_table = MyCountTable()\n",
    "# first time \n",
    "%time count_table.fset_generate_count_tables(base_fset, [], COUNT_TABLE_FILE)\n",
    "# load previously generated\n",
    "# %time count_table.load_count_tables(COUNT_TABLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# counting of base feature set\n",
    "BASE_CNT_LS_FSET_FILE = './cache/basec_ls_fset.pickle'\n",
    "class BaseCntLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        n_bf = len(base_fset.fname_list)\n",
    "        n_train = base_fset.Xtrain.shape[0]\n",
    "        n_test = base_fset.Xtest.shape[0]\n",
    "        self.Xtrain = np.zeros((n_train, n_bf), float)\n",
    "        self.Xtest = np.zeros((n_test, n_bf), float)\n",
    "        for i in xrange(n_bf):\n",
    "            self.Xtrain[:, i], self.Xtest[:, i] = \\\n",
    "                count_table.fset_one_degree_counts(base_fset, i, COUNT_TABLE_FILE)\n",
    "        myclassify.np_numeric_transform(self.Xtrain, self.Xtest, [], 'log', True)\n",
    "        self.fname_list = [u'CNT_'+fname+u'_LS' for fname in base_fset.fname_list[1:]]\n",
    "        self.find_list = range(len(self.fname_list)+1)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "basec_ls_fset = BaseCntLSFeatureSet()\n",
    "%time basec_ls_fset.load_feature_set(BASE_CNT_LS_FSET_FILE)\n",
    "print basec_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# percentage of certain resources used by other parties\n",
    "\n",
    "RSRC_PER_LS_FSET_FILE = './cache/rsrcp_ls_fset.pickle'\n",
    "class RsrcPerLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        n_bf = len(base_fset.fname_list)\n",
    "        n_train = base_fset.Xtrain.shape[0]\n",
    "        n_test = base_fset.Xtest.shape[0]\n",
    "        self.Xtrain = np.zeros((n_train, n_bf-1), float)\n",
    "        self.Xtest = np.zeros((n_test, n_bf-1), float)\n",
    "        for i in xrange(1, n_bf):\n",
    "            self.Xtrain[:, i-1], self.Xtest[:, i-1] = \\\n",
    "                count_table.fset_two_degree_counts(base_fset, i, 0, 'per', COUNT_TABLE_FILE)\n",
    "        myclassify.np_numeric_transform(self.Xtrain, self.Xtest, [], 'log', True)\n",
    "        self.fname_list = [u'RSRC_PER_'+fname+u'_LS' for fname in base_fset.fname_list[1:]]\n",
    "        self.find_list = range(len(self.fname_list)+1)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "%time rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "print rsrcp_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# different kinds of resources used by other parties\n",
    "RSRC_NUM_LS_FSET_FILE = './cache/rsrcn_ls_fset.pickle'\n",
    "class RsrcNumLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        n_bf = len(base_fset.fname_list)\n",
    "        n_train = base_fset.Xtrain.shape[0]\n",
    "        n_test = base_fset.Xtest.shape[0]\n",
    "        self.Xtrain = np.zeros((n_train, n_bf-1), float)\n",
    "        self.Xtest = np.zeros((n_test, n_bf-1), float)\n",
    "        for i in xrange(1, n_bf):\n",
    "            self.Xtrain[:, i-1], self.Xtest[:, i-1] = \\\n",
    "                count_table.fset_two_degree_counts(base_fset, i, 0, 'num', COUNT_TABLE_FILE)\n",
    "        myclassify.np_numeric_transform(self.Xtrain, self.Xtest, [], 'log', True)\n",
    "        self.fname_list = [u'RSRC_NUM_'+fname+u'_LS' for fname in base_fset.fname_list[1:]]\n",
    "        self.find_list = range(len(self.fname_list)+1)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "%time rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "print rsrcn_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of other parties used by certain manager\n",
    "MGR_UNUM_LS_FSET_FILE = './cache/mgrun_ls_fset.pickle'\n",
    "class MgrUNumLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        n_bf = len(base_fset.fname_list)\n",
    "        n_train = base_fset.Xtrain.shape[0]\n",
    "        n_test = base_fset.Xtest.shape[0]\n",
    "        self.Xtrain = np.zeros((n_train, n_bf-2), float)\n",
    "        self.Xtest = np.zeros((n_test, n_bf-2), float)\n",
    "        for i in xrange(2, n_bf):\n",
    "            self.Xtrain[:, i-2], self.Xtest[:, i-2] = \\\n",
    "                count_table.fset_two_degree_counts(base_fset, 1, i, 'num', COUNT_TABLE_FILE)\n",
    "            self.fname_list.append(u'MGR_UNUM_'+base_fset.fname_list[i]+u'_LS')\n",
    "        myclassify.np_numeric_transform(self.Xtrain, self.Xtest, [], 'log', True)\n",
    "        self.find_list = range(len(self.fname_list)+1)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "mgrun_ls_fset = MgrUNumLSFeatureSet()\n",
    "%time mgrun_ls_fset.generate_feature_set(MGR_UNUM_LS_FSET_FILE)\n",
    "print mgrun_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of other parties used by certain department\n",
    "DEPT_UNUM_LS_FSET_FILE = './cache/deptun_ls_fset.pickle'\n",
    "class DeptUNumLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        n_bf = len(base_fset.fname_list)\n",
    "        n_train = base_fset.Xtrain.shape[0]\n",
    "        n_test = base_fset.Xtest.shape[0]\n",
    "        self.Xtrain = np.zeros((n_train, n_bf-2), float)\n",
    "        self.Xtest = np.zeros((n_test, n_bf-2), float)\n",
    "        col = 0\n",
    "        for i in xrange(1, n_bf):\n",
    "            if i == 3:\n",
    "                continue\n",
    "            self.Xtrain[:, col], self.Xtest[:, col] = \\\n",
    "                count_table.fset_two_degree_counts(base_fset, 3, i, 'num', COUNT_TABLE_FILE)\n",
    "            col += 1\n",
    "            self.fname_list.append(u'DEPT_UNUM_'+base_fset.fname_list[i]+u'_LS')\n",
    "        myclassify.np_numeric_transform(self.Xtrain, self.Xtest, [], 'log', True)\n",
    "        \n",
    "        self.find_list = range(len(self.fname_list)+1)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "        \n",
    "deptun_ls_fset = DeptUNumLSFeatureSet()\n",
    "%time deptun_ls_fset.load_feature_set(DEPT_UNUM_LS_FSET_FILE)\n",
    "print deptun_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base plus the two feature sets related with resources\n",
    "BASIC_TREE_LS_FSET_FILE = './cache/btree_ls_fset.pickle'\n",
    "class BasicTreeLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "        rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "        rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "        rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "        \n",
    "        self.fname_list, self.find_list, self.Xtrain, self.Xtest = \\\n",
    "            myclassify.concat_feature_set([base_fset, rsrcn_ls_fset, rsrcp_ls_fset])\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "btree_ls_fset = BasicTreeLSFeatureSet()\n",
    "%time btree_ls_fset.load_feature_set(BASIC_TREE_LS_FSET_FILE)\n",
    "print btree_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base with rare event combined plus the two feature sets related with resources\n",
    "CRBASIC_TREE_LS_FSET_FILE = './cache/crbtree_ls_fset.pickle'\n",
    "class CRBasicTreeLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        crbase_fset = CRBaseFeatureSet()\n",
    "        crbase_fset.load_feature_set(CRBASE_FSET_FILE)\n",
    "        rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "        rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "        rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "        rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "        \n",
    "        self.fname_list, self.find_list, self.Xtrain, self.Xtest = \\\n",
    "            myclassify.concat_feature_set([crbase_fset, rsrcn_ls_fset, rsrcp_ls_fset])\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "crbtree_ls_fset = CRBasicTreeLSFeatureSet()\n",
    "%time crbtree_ls_fset.load_feature_set(CRBASIC_TREE_LS_FSET_FILE)\n",
    "print crbtree_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic tree plus manager\n",
    "BASICM_TREE_LS_FSET_FILE = './cache/bmtree_ls_fset.pickle'\n",
    "class BasicMTreeLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "        rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "        rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "        rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "        mgrun_ls_fset = MgrUNumLSFeatureSet()\n",
    "        mgrun_ls_fset.load_feature_set(MGR_UNUM_LS_FSET_FILE)\n",
    "        \n",
    "        self.fname_list, self.find_list, self.Xtrain, self.Xtest = \\\n",
    "            myclassify.concat_feature_set([base_fset, rsrcn_ls_fset, rsrcp_ls_fset, mgrun_ls_fset])\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "bmtree_ls_fset = BasicMTreeLSFeatureSet()\n",
    "%time bmtree_ls_fset.load_feature_set(BASICM_TREE_LS_FSET_FILE)\n",
    "print bmtree_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic tree plus manager and department\n",
    "BASICMD_TREE_LS_FSET_FILE = './cache/bmdtree_ls_fset.pickle'\n",
    "class BasicMDTreeLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "        rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "        rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "        rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "        mgrun_ls_fset = MgrUNumLSFeatureSet()\n",
    "        mgrun_ls_fset.load_feature_set(MGR_UNUM_LS_FSET_FILE)\n",
    "        deptun_ls_fset = DeptUNumLSFeatureSet()\n",
    "        deptun_ls_fset.load_feature_set(DEPT_UNUM_LS_FSET_FILE)\n",
    "        \n",
    "        self.fname_list, self.find_list, self.Xtrain, self.Xtest = \\\n",
    "            myclassify.concat_feature_set([base_fset, rsrcn_ls_fset, rsrcp_ls_fset, mgrun_ls_fset, deptun_ls_fset])\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "bmdtree_ls_fset = BasicMDTreeLSFeatureSet()\n",
    "%time bmdtree_ls_fset.load_feature_set(BASICMD_TREE_LS_FSET_FILE)\n",
    "print bmdtree_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic tree plus manager , deparment and counting of base feature\n",
    "BASICCMD_TREE_LS_FSET_FILE = './cache/bcmdtree_ls_fset.pickle'\n",
    "class BasicCMDTreeLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        base_fset = BaseFeatureSet()\n",
    "        base_fset.load_feature_set(BASE_FSET_FILE)\n",
    "        basec_ls_fset = BaseCntLSFeatureSet()\n",
    "        basec_ls_fset.load_feature_set(BASE_CNT_LS_FSET_FILE)\n",
    "        rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "        rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "        rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "        rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "        mgrun_ls_fset = MgrUNumLSFeatureSet()\n",
    "        mgrun_ls_fset.load_feature_set(MGR_UNUM_LS_FSET_FILE)\n",
    "        deptun_ls_fset = DeptUNumLSFeatureSet()\n",
    "        deptun_ls_fset.load_feature_set(DEPT_UNUM_LS_FSET_FILE)\n",
    "        \n",
    "        fset_list = [base_fset, basec_ls_fset, rsrcn_ls_fset, rsrcp_ls_fset, mgrun_ls_fset, deptun_ls_fset]\n",
    "        \n",
    "        self.fname_list, self.find_list, self.Xtrain, self.Xtest = \\\n",
    "            myclassify.concat_feature_set(fset_list)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "bcmdtree_ls_fset = BasicCMDTreeLSFeatureSet()\n",
    "%time bcmdtree_ls_fset.load_feature_set(BASICCMD_TREE_LS_FSET_FILE)\n",
    "print bcmdtree_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot version of the above, can be used fro logistic\n",
    "OHBASICCMD_TREE_LS_FSET_FILE = './cache/ohbcmdlr_ls_fset.pickle'\n",
    "class OHBasicCMDTreeLSFeatureSet(MyFeatureSet):\n",
    "    def generate_feature_set(self, file_path = None):\n",
    "        ohbase_fset = OHBaseFeatureSet()\n",
    "        ohbase_fset.load_feature_set(OHBASE_FSET_FILE)\n",
    "        basec_ls_fset = BaseCntLSFeatureSet()\n",
    "        basec_ls_fset.load_feature_set(BASE_CNT_LS_FSET_FILE)\n",
    "        rsrcn_ls_fset = RsrcNumLSFeatureSet()\n",
    "        rsrcn_ls_fset.load_feature_set(RSRC_NUM_LS_FSET_FILE)\n",
    "        rsrcp_ls_fset = RsrcPerLSFeatureSet()\n",
    "        rsrcp_ls_fset.load_feature_set(RSRC_PER_LS_FSET_FILE)\n",
    "        mgrun_ls_fset = MgrUNumLSFeatureSet()\n",
    "        mgrun_ls_fset.load_feature_set(MGR_UNUM_LS_FSET_FILE)\n",
    "        deptun_ls_fset = DeptUNumLSFeatureSet()\n",
    "        deptun_ls_fset.load_feature_set(DEPT_UNUM_LS_FSET_FILE)\n",
    "        \n",
    "        fset_list = [ohbase_fset, basec_ls_fset, rsrcn_ls_fset, rsrcp_ls_fset, mgrun_ls_fset, deptun_ls_fset]\n",
    "        \n",
    "        self.fname_list, self.find_list, self.Xtrain, self.Xtest = \\\n",
    "            myclassify.concat_feature_set(fset_list)\n",
    "        \n",
    "        if file_path:\n",
    "            self.save_feature_set(file_path)\n",
    "\n",
    "ohbcmdtree_ls_fset = OHBasicCMDTreeLSFeatureSet()\n",
    "%time ohbcmdtree_ls_fset.load_feature_set(OHBASICCMD_TREE_LS_FSET_FILE)\n",
    "print ohbcmdtree_ls_fset.fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate ytrain and idtest\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "ytrain = df_train[u'ACTION'].values\n",
    "idtest = df_test[u'id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate xgb prediction using bcmdtree_ls_fset\n",
    "myxgb_params = {'objective': 'binary:logistic', 'subsample': .9, 'nthread': 4, 'seed': SEED, 'num_round':1000,\n",
    "                   'learning_rate': 0.03, 'n_estimators': 1000, 'colsample_bylevel':0.7, \n",
    "                   'max_depth': 20,'gamma': 0.6, 'colsample_bytree':0.85, 'min_child_weight':0.,\n",
    "                      'lambda': 0.8, 'alpha': 0}\n",
    "\n",
    "myxgb = myclassify.MyXGBoost(myxgb_params)\n",
    "\n",
    "myxgb.fit(bcmdtree_ls_fset.Xtrain, ytrain)\n",
    "\n",
    "myxgb_ypred = myxgb.predict_proba(bcmdtree_ls_fset.Xtest)\n",
    "\n",
    "submission = pd.DataFrame({\"id\":idtest, \"ACTION\":myxgb_ypred})\n",
    "submission = submission[['id', 'ACTION']]\n",
    "submission.to_csv(\"xgb_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate logistic regression prediction using ohbcmdtree_ls_fset\n",
    "mylr_params = {'C': 2., 'n_jobs':-1, 'penalty':'l2', \n",
    "               'solver':'liblinear', 'max_iter':1000 , 'tol':1e-10, 'random_state':SEED, 'verbose':0}\n",
    "\n",
    "mylr = myclassify.MyLogisticReg(mylr_params)\n",
    "\n",
    "mylr.fit(ohbcmdtree_ls_fset.Xtrain, ytrain)\n",
    "\n",
    "mylr_ypred = mylr.predict_proba(ohbcmdtree_ls_fset.Xtest)\n",
    "\n",
    "submission = pd.DataFrame({\"id\":idtest, \"ACTION\":mylr_ypred})\n",
    "submission = submission[['id', 'ACTION']]\n",
    "submission.to_csv(\"lr_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
